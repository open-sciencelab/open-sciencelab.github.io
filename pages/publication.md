---

layout: page

show_meta: false

title: "Publications"

subheadline: ""

teaser: 

header:

   image_fullwidth: 

permalink: "/publications/"

---

## AI for Science

### Preprint Papers

Chaoqi Liang, Weiqiang Bai, Lifeng Qiao, et. al,
"Rethinking the BERT-like Pretraining for DNA Sequences",
arXiv, 2023. 
[[paper](https://arxiv.org/abs/2310.07644)] 

Tao Shen, Zhihang Hu, Zhangzhi Peng, et. al, 
"E2Efold-3D: End-to-End Deep Learning Method for accurate de novo RNA 3D Structure Prediction", 
arXiv, 2022. 
[[paper](https://arxiv.org/abs/2207.01586)] 

Jiayang Chen, Zhihang Hu, Siqi Sun, et. al,
"Interpretable RNA Foundation Model from Unannotated Data for Highly Accurate RNA Structure and Function Predictions",
bioRxiv, 2022. 
[[paper](https://www.biorxiv.org/content/10.1101/2022.08.06.503062v2.full)] 
[[code](https://github.com/ml4bio/RNA-FM)]

Hongtai Jing, Zhengtao Gao, Sheng Xu, et. al,
"Accurate Prediction of Antibody Function and Structure Using Bio-Inspired Antibody Language Model",
bioRxiv, 2023. 
[[paper](https://www.biorxiv.org/content/10.1101/2023.08.30.555473v1.full)] 
[[code](https://github.com/BEAM-Labs/BALM)]

Zhongju Yuan, Tao Shen, Sheng Xu, et. al,
"AF2-Mutation: Adversarial Sequence Mutations against AlphaFold2 on Protein Tertiary Structure Prediction",
arXiv, 2023. 
[[paper](https://arxiv.org/abs/2305.08929)]

Le Zhang, Jiayang Chen, Tao Shen, et. al,
"Enhancing the Protein Tertiary Structure Prediction by Multiple Sequence Alignment Generation",
arXiv, 2023. 
[[paper](https://arxiv.org/abs/2306.01824)] 
[[code](https://github.com/Magiccircuit/MSA-Augmentor)]

Kang Chen, Tao Han, Junchao Gong, et. al,
"FengWu: Pushing the Skillful Global Medium-range Weather Forecast beyond 10 Days Lead",
arXiv, 2023. 
[[paper](https://arxiv.org/abs/2304.02948)] 



### Journal Papers

Zheqi Li, Hongjin Shi, Xueying Chen, et. al,
"Nickel-Catalyzed Regio- and Enantioselective Borylative Coupling of Terminal Alkenes with Alkyl Halides Enabled by an Anionic Bisoxazoline Ligand",
Journal of the American Chemical Society (JACS) 2023, 145, 25, 13603–13614. 
[[paper](https://pubs.acs.org/doi/10.1021/jacs.3c01040)] 

Dong Wu, Weiyu Kong, Yang Bao, et. al,
"Alkene 1,1-difunctionalizations via organometallic-radical relay",
Nature Catalysis, 2023, 6, 11, 1030–1041. 
[[paper](https://www.nature.com/articles/s41929-023-01032-0)] 


Yaning Cui, Kang Chen, Lingyao Zhang, et. al,
"Atomic Positional Embedding-Based Transformer Model for Predicting the Density of States of Crystalline Materials",
The Journal of Physical Chemistry Letters, 2023, 14, 35, 7924–7930. 
[[paper](https://www.nature.com/articles/s41929-023-01032-0)] 


### Conference Papers

"The Logarithm Trick: achieve better long term forecast via Mean Logarithm Square Loss",
ICLR, 2024. 
[[paper](https://openreview.net/forum?id=Y29rdPpPu4)]

Linglin Jing, Sheng Xu, Yifan Wang, et. al,
"CrossBind: Collaborative Cross-Modal Identification of Protein Nucleic-Acid-Binding Residues",
AAAI, 2024. 
[[paper](https://arxiv.org/abs/2312.12094)]
[[code](https://github.com/BEAM-Labs/CrossBind)]

Zhi Jin, Sheng Xu, Xiang Zhang, et. al,
"ContraNovo: A Contrastive Learning Approach to Enhance De Novo Peptide Sequencing",
AAAI, 2024.
[[paper](https://arxiv.org/abs/2312.11584)]
[[code](https://github.com/BEAM-Labs/ContraNovo)]

<br />

## 3D Vision

### Preprint Papers

Yunhan Yang, Yukun Huang, Xiaoyang Wu, et. al,
"DreamComposer: Controllable 3D Object Generation via Multi-View Conditions",
arXiv, 2023.
[[paper](https://arxiv.org/abs/2312.03611)]

Yizhou Wang, Yixuan Wu, Shixiang Tang, et. al,
"Hulk: A Universal Knowledge Translator for Human-Centric Tasks",
arXiv, 2023.
[[paper](https://arxiv.org/abs/2312.01697)]
[[code](https://github.com/OpenGVLab/HumanBench)]

Yan Lu, Xinzhu Ma, Lei Yang, et. al,
"GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D Object Detection",
arXiv, 2023.
[[paper](https://arxiv.org/abs/2310.15624)]

Haoyi Zhu, Honghui Yang, Xiaoyang Wu, et. al,
"PonderV2: Pave the Way for 3D Foundation Model with A Universal Pre-training Paradigm",
arXiv, 2023.
[[paper](https://arxiv.org/abs/2310.08586)]
[[code](https://github.com/OpenGVLab/PonderV2)]

Honghui Yang, Sha Zhang, Di Huang, et. al,
"UniPad: A Universal Pre-Training Paradigm For Autonomous Driving",
arXiv, 2023.
[[paper](https://arxiv.org/abs/2310.08370)]
[[code](https://github.com/Nightmare-n/UniPAD)]



### Journal Papers

"Accurate Registration of Cross-Modality Geometry via Consistent Clustering",
TVCG, 2023.
[[paper](https://ieeexplore.ieee.org/document/10049688)]
[[code](https://github.com/zikai1/CrossModReg)]

"Cross-source Point Cloud Registration: Challenges, Progress and Prospects",
Neurocomputing, 2023.
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S0925231223005064)]
[[code](https://github.com/XiaoshuiHuang/GMF)]

"GMF: General Multimodal Fusion Framework for Correspondence Outlier Rejection. ",
IEEE Robotics and Automation Letters, 2022.
[[paper](https://ieeexplore.ieee.org/abstract/document/9940574)]

"IMFNet: Interpretable Multimodal Fusion for Point Cloud Registration",
IEEE Robotics and Automation Letters, 2022.
[[paper](https://ieeexplore.ieee.org/document/9919364)]

"Robust real-world point cloud registration by inlier detection",
CVIU, 2022.
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S1077314222001345)]

"Unsupervised Point Cloud Registration by Learning Unified Gaussian Mixture Models",
IEEE Robotics and Automation Letters, 2022.
[[paper](https://ieeexplore.ieee.org/document/9790333)]

"Network Pruning via Resource Reallocation",
Pattern Recognition, 2023.
[[paper](https://arxiv.org/abs/2103.01847)]
[[code](https://github.com/cardwing/Codes-for-PEEL)]

Yifan Zuo, Yaping Xu, Yifeng Zeng, et. al,
"A2GSTran: Depth Map Super-resolution via Asymmetric Attention with Guidance Selection",
TCSVT, 2023.
[[paper](https://ieeexplore.ieee.org/abstract/document/10296875)]
[[code](https://github.com/alex-cate/Depth_Map_Super-resolution_via_Asymmetric_Attention_with_Guidance_Selection)]


### Conference Papers

Xiaoshui Huang, Zhou Huang, Sheng Li, et. al,
"EPCL: Frozen CLIP Transformer is An Efficient Point Cloud Encoder",
AAAI, 2024.
[[paper](https://arxiv.org/abs/2212.04098)]
[[code](https://github.com/XiaoshuiHuang/EPCL)]

Zhenfei Yin, Jiong Wang, Jianjian Cao, et. al,
"LAMM: LanguageAssisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark",
NeurIPS, 2023.
[[paper](https://arxiv.org/abs/2306.06687)]

Tianyu Huang, Bowen Dong, Yunhan Yang, et. al,
"CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-training",
ICCV, 2023.
[[paper](https://arxiv.org/abs/2210.01055)]

Guofeng Mei, Hao Tang, Xiaoshui Huang, et. al,
"Unsupervised Deep Probabilistic Approach for Partial Point Cloud Registration",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2303.13290)]

Mingzhi Yuan, Xiaoshui Huang, Kexue Fu, et. al,
"Boosting 3D Point Cloud Registration by Transferring Multi-modality Knowledge",
ICRA, 2023.
[[paper](https://ieeexplore.ieee.org/document/10161411)]
[[code](https://github.com/phdymz/DBENet)]

Yingjie Wang, Jiajun Deng, Yuenan Hou, et. al,
"CluB: Cluster Meets BEV for LiDAR-Based 3D Object Detection",
NeurIPS, 2023.
[[paper](https://openreview.net/forum?id=jIhX7SpfCz)]

Yeqi Bai, Ben Fei, Youquan Liu, et. al,
"RangePerception: Taming LiDAR Range View for Efficient and Accurate 3D Object Detection",
NeurIPS, 2023.
[[paper](https://openreview.net/forum?id=9kFQEJSyCM)]

Lingdong Kong, Youquan Liu, Runnan Chen, et. al,
"Rethinking Range View Representation for LiDAR Segmentation",
ICCV, 2023.
[[paper](https://arxiv.org/abs/2303.05367)]

Yuenan Hou, Xinge Zhu, Yuexin Ma, et. al,
"Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2206.02099)]
[[code](https://github.com/cardwing/Codes-for-PVKD)]

Youquan Liu, Runnan Chen, Xin Li, et. al,
"UniSeg: A Unified Multi-Modal LiDAR Segmentation Network and the OpenPCSeg Codebase",
ICCV, 2023.
[[paper](https://arxiv.org/abs/2309.05573)]
[[code](https://github.com/PJLab-ADG/PCSeg)]

Zhaoyang Xia, Youquan Liu, Xin Li, et. al,
"SCPNet: Semantic Scene Completion on Point Cloud",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2303.06884)]


Runnan Chen, Youquan Liu, Lingdong Kong, et. al,
"CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2301.04926)]
[[code](https://github.com/runnanchen/CLIP2Scene)]

Xin Li, Tao Ma, Yuenan Hou, et. al,
"LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2303.03595v2)]
[[code](https://github.com/sankin97/LoGoNet)]

Xin Li, Botian Shi, Yuenan Hou, et. al,
"Homogeneous Multi-modal Feature Fusion and Interaction for 3D Object Detection",
ECCV, 2022.
[[paper](https://arxiv.org/abs/2210.09615)]


Guodong Xu, Yuenan Hou, Ziwei Liu, et. al,
"Mind the Gap in Distilling StyleGANs",
ECCV, 2022.
[[paper](https://arxiv.org/abs/2208.08840)]


Peishan Cong, Xinge Zhu, Feng Qiao, et. al,
"STCrowd: A Multimodal Dataset for Pedestrian Perception in Crowded Scenes",
CVPR, 2022.
[[paper](https://arxiv.org/abs/2204.01026)]


Yiteng Xu, Peishan Cong, Yichen Yao, et. al,
"Human-centric Scene Understanding for 3D Large-scale Scenarios",
ICCV, 2023.
[[paper](https://arxiv.org/abs/2307.14392)]


Yuhang Lu, Qi Jiang, Runnan Chen, et. al,
"See More and Know More: Zero-shot Point Cloud Segmentation via Multi-modal Visual Data",
ICCV, 2023.
[[paper](https://arxiv.org/abs/2307.10782)]


Xiaohan Xing, Zhen Chen, Yuenan Hou, et. al,
"Gradient Modulated Contrastive Distillation of Low-Rank Multi-Modal Knowledge for Disease Diagnosis",
Medical Image Analysis, 2023.
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S1361841523001342)]


Yan Peng, Xiaogang Tang, Yiqing Zhou, et. al,
"How to Tame Mobility in Federated Learning over Mobile Networks?",
IEEE Transactions on Wireless Communications, 2023.
[[paper](https://ieeexplore.ieee.org/document/10128968)]


Xiaohan Xing, Zhen Chen, Meilu Zhu, et. al,
"Discrepancy and Gradient-guided Multi-modal Knowledge Distillation for Pathological Glioma Grading",
MICCAI, 2023.
[[paper](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_61)]
[[code](https://github.com/CityU-AIM-Group/MultiModal-learning)]

Di Huang, Sida Peng, Tong He, et. al,
"Ponder: Point Cloud Pre-training via Neural Rendering",
ICCV, 2023.
[[paper](https://arxiv.org/abs/2301.00157)]


Honghui Yang, Wenxiao Wang, Minghao Chen, et. al,
"PVT-SSD: Single-Stage 3D Object Detector with Point-Voxel Transformer",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2305.06621)]
[[code](https://github.com/Nightmare-n/PVT-SSD)]

Honghui Yang, Tong He, Jiaheng Liu, et. al,
"GD-MAE: Generative Decoder for MAE Pre-training on LiDAR Point Clouds",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2212.03010)]
[[code](https://github.com/Nightmare-n/GD-MAE)]

Mingye Xu, Mutian Xu, Tong He, et. al,
"MM-3DScene: 3D Scene Understanding by Customizing Masked Modeling with Informative-Preserved Reconstruction and Self-Distilled Consistency",
CVPR, 2023.
[[paper](https://arxiv.org/abs/2212.09948)]



## Other Topics

> 2D vision, ML, LLM, etc.


### Preprint Papers

Pumeng Lyu, Tao Tang, Fenghua Ling, et. al,
"ResoNet: Robust and Explainable ENSO Forecasts with Hybrid Convolution and Transformer Networks",
arXiv, 2023.
[[paper](https://arxiv.org/abs/2312.10429)]


### Journals

Honghui Yang, Tong He, Jiaheng Liu, et. al,
"Continuous Cross-resolution Remote Sensing Image Change Detection",
IEEE TGRS, 2023.
[[paper](https://arxiv.org/abs/2212.03010)]
[[code](https://github.com/justchenhao/SILI_CD)]


### Conferences

Tao Han, Lei Bai, Lingbo Liu, et. al,
"STEERER: Resolving Scale Variations for Counting and Localization via Selective Inheritance Learning",
ICCV, 2023.
[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_STEERER_Resolving_Scale_Variations_for_Counting_and_Localization_via_Selective_ICCV_2023_paper.pdf)]
[[code](https://github.com/taohan10200/STEERER)]

Zhenfei Yin, Jiong Wang, Jianjian Cao, et. al,
"LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark ",
NeurIPS, 2023.
[[paper](https://arxiv.org/abs/2306.06687)]
[[code](https://github.com/OpenGVLab/LAMM)]
[[demo](http://106.14.2.150:10005/)]

